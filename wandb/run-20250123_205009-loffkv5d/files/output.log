Classes:  ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']
C:\Users\ahmed\.conda\envs\brainTumor_env\Lib\site-packages\keras\src\layers\preprocessing\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
[34m[1mwandb[0m: [33mWARNING[0m When using `save_best_only`, ensure that the `filepath` argument contains formatting placeholders like `{epoch:02d}` or `{batch:02d}`. This ensures correct interpretation of the logged artifacts.
[1mModel: "sequential_1"[0m
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m [0m[1mLayer (type)                        [0m[1m [0mâ”ƒ[1m [0m[1mOutput Shape               [0m[1m [0mâ”ƒ[1m [0m[1m        Param #[0m[1m [0mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ sequential ([38;5;33mSequential[0m)              â”‚ ([38;5;45mNone[0m, [38;5;34m180[0m, [38;5;34m180[0m, [38;5;34m3[0m)         â”‚               [38;5;34m0[0m â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ rescaling ([38;5;33mRescaling[0m)                â”‚ ([38;5;45mNone[0m, [38;5;34m180[0m, [38;5;34m180[0m, [38;5;34m3[0m)         â”‚               [38;5;34m0[0m â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d ([38;5;33mConv2D[0m)                      â”‚ ([38;5;45mNone[0m, [38;5;34m178[0m, [38;5;34m178[0m, [38;5;34m32[0m)        â”‚             [38;5;34m896[0m â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d ([38;5;33mMaxPooling2D[0m)         â”‚ ([38;5;45mNone[0m, [38;5;34m89[0m, [38;5;34m89[0m, [38;5;34m32[0m)          â”‚               [38;5;34m0[0m â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 ([38;5;33mConv2D[0m)                    â”‚ ([38;5;45mNone[0m, [38;5;34m87[0m, [38;5;34m87[0m, [38;5;34m64[0m)          â”‚          [38;5;34m18,496[0m â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1 ([38;5;33mMaxPooling2D[0m)       â”‚ ([38;5;45mNone[0m, [38;5;34m43[0m, [38;5;34m43[0m, [38;5;34m64[0m)          â”‚               [38;5;34m0[0m â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 ([38;5;33mConv2D[0m)                    â”‚ ([38;5;45mNone[0m, [38;5;34m41[0m, [38;5;34m41[0m, [38;5;34m128[0m)         â”‚          [38;5;34m73,856[0m â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2 ([38;5;33mMaxPooling2D[0m)       â”‚ ([38;5;45mNone[0m, [38;5;34m20[0m, [38;5;34m20[0m, [38;5;34m128[0m)         â”‚               [38;5;34m0[0m â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout ([38;5;33mDropout[0m)                    â”‚ ([38;5;45mNone[0m, [38;5;34m20[0m, [38;5;34m20[0m, [38;5;34m128[0m)         â”‚               [38;5;34m0[0m â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten ([38;5;33mFlatten[0m)                    â”‚ ([38;5;45mNone[0m, [38;5;34m51200[0m)               â”‚               [38;5;34m0[0m â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense ([38;5;33mDense[0m)                        â”‚ ([38;5;45mNone[0m, [38;5;34m128[0m)                 â”‚       [38;5;34m6,553,728[0m â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 ([38;5;33mDense[0m)                      â”‚ ([38;5;45mNone[0m, [38;5;34m4[0m)                   â”‚             [38;5;34m516[0m â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1m Total params: [0m[38;5;34m6,647,492[0m (25.36 MB)
[1m Trainable params: [0m[38;5;34m6,647,492[0m (25.36 MB)
[1m Non-trainable params: [0m[38;5;34m0[0m (0.00 B)
Epoch 1/10
[1m72/72[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m33s[0m 432ms/step - accuracy: 0.4211 - loss: 1.4320 - val_accuracy: 0.6028 - val_loss: 0.9826
Epoch 2/10
[1m72/72[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m32s[0m 439ms/step - accuracy: 0.5717 - loss: 0.9901 - val_accuracy: 0.6899 - val_loss: 0.7956
Epoch 3/10
[1m72/72[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m31s[0m 436ms/step - accuracy: 0.6291 - loss: 0.8460 - val_accuracy: 0.7091 - val_loss: 0.6806
Epoch 4/10
[1m72/72[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m31s[0m 435ms/step - accuracy: 0.6983 - loss: 0.7095 - val_accuracy: 0.7544 - val_loss: 0.5939
Epoch 5/10
[1m72/72[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m32s[0m 447ms/step - accuracy: 0.7402 - loss: 0.6480 - val_accuracy: 0.7456 - val_loss: 0.5900
Epoch 6/10
[1m72/72[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m32s[0m 439ms/step - accuracy: 0.7422 - loss: 0.6298 - val_accuracy: 0.7753 - val_loss: 0.5509
Epoch 7/10
[1m72/72[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m32s[0m 450ms/step - accuracy: 0.7511 - loss: 0.5897 - val_accuracy: 0.7805 - val_loss: 0.5011
Epoch 8/10
[1m72/72[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m32s[0m 443ms/step - accuracy: 0.7971 - loss: 0.5232 - val_accuracy: 0.7927 - val_loss: 0.5307
Epoch 9/10
[1m72/72[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m32s[0m 437ms/step - accuracy: 0.7875 - loss: 0.5288 - val_accuracy: 0.8031 - val_loss: 0.5217
Epoch 10/10
[1m72/72[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m32s[0m 445ms/step - accuracy: 0.7975 - loss: 0.4718 - val_accuracy: 0.8049 - val_loss: 0.4954
[1m13/13[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 87ms/step - accuracy: 0.3376 - loss: 3.5208
Test Loss: 2.114785671234131, Test Accuracy: 0.48984771966934204
